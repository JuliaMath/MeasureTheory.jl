var documenterSearchIndex = {"docs":
[{"location":"intro/","page":"Introduction","title":"Introduction","text":"There are lots of packages for working with probability distributions. But very often, we need to work with \"distributions\" that really aren't. ","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"For example, the correspondence between regularization and Bayesian prior distributions leads naturally to the idea of extending probabilistic programming systems to cover both. But it's easy to come up with a loss function for which the integral of the corresponding \"prior\" is infinite! The result is not really a distirbution. It is, however, still a measure.","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"Even restricted to Bayesian methods, users might sometimes want to use an improper prior. By definition, these cannot be integrated over their domain. But an improper prior is still a measure.","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"In Markov chain Monte Carlo (MCMC), we often work with distributions for which we can only caluculate  the log-density up to an additive constant. Considering this instead as a measure can be helpful. Even better, consdering intermediate computations along the way as computations on measures saves us from computing normalization terms where the end result will discard this anyway.","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"To be clear, that's not to say that we always discard normalizations. Rather, they're considered as belonging to the measure itself, rather than being included in each sub-computation. If measures you work with happen to also be probability distributions, you'll always be able to recover those results.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = MeasureTheory","category":"page"},{"location":"#MeasureTheory","page":"Home","title":"MeasureTheory","text":"","category":"section"},{"location":"#API","page":"Home","title":"API","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [MeasureTheory]","category":"page"},{"location":"#MeasureTheory.Density","page":"Home","title":"MeasureTheory.Density","text":"struct Density{M,B}\n    Œº::M\n    base::B\nend\n\nFor measures Œº and ŒΩ with Œº‚â™ŒΩ, the density of Œº with respect to ŒΩ (also called the Radon-Nikodym derivative dŒº/dŒΩ) is a function f defined on the support of ŒΩ with the property that for any measurable a ‚äÇ supp(ŒΩ), Œº(a) = ‚à´‚Çê f dŒΩ.\n\nBecause this function is often difficult to express in closed form, there are many different ways of computing it. We therefore provide a formal representation to allow comptuational flexibilty.\n\n\n\n\n\n","category":"type"},{"location":"#MeasureTheory.DensityMeasure","page":"Home","title":"MeasureTheory.DensityMeasure","text":"struct DensityMeasure{F,B} <: AbstractMeasure\n    density :: F\n    base    :: B\nend\n\nA DensityMeasure is a measure defined by a density with respect to some other \"base\" measure \n\n\n\n\n\n","category":"type"},{"location":"#MeasureTheory.Kernel","page":"Home","title":"MeasureTheory.Kernel","text":"kernel(f, M)\nkernel((f1, f2, ...), M)\n\nA kernel Œ∫ = kernel(f, m) returns a wrapper around a function f giving the parameters for a measure of type M, such that Œ∫(x) = M(f(x)...) respective Œ∫(x) = M(f1(x), f2(x), ...)\n\nIf the argument is a named tuple (;a=f1, b=f1), Œ∫(x) is defined as M(;a=f(x),b=g(x)).\n\nReference\n\nhttps://en.wikipedia.org/wiki/Markov_kernel\n\n\n\n\n\n","category":"type"},{"location":"#MeasureTheory.PowerMeasure","page":"Home","title":"MeasureTheory.PowerMeasure","text":"struct PowerMeasure{M,N}\n    Œº::M\n    size::NTuple{N,Int}\nend\n\nA power measure is a product of a measure with itself. The number of elements in the product determines the dimensionality of the resulting support.\n\nNote that power measures are only well-defined for integer powers.\n\nThe nth power of a measure Œº can be written Œº^x.\n\n\n\n\n\n","category":"type"},{"location":"#MeasureTheory.SuperpositionMeasure","page":"Home","title":"MeasureTheory.SuperpositionMeasure","text":"struct SuperpositionMeasure{X,NT} <: AbstractMeasure\n    components :: NT\nend\n\nSuperposition of measures is analogous to mixture distributions, but (because measures need not be normalized) requires no scaling.\n\nThe superposition of two measures Œº and ŒΩ can be more concisely written as Œº + ŒΩ.\n\n\n\n\n\n","category":"type"},{"location":"#MeasureTheory.WeightedMeasure","page":"Home","title":"MeasureTheory.WeightedMeasure","text":"struct WeightedMeasure{R,M} <: AbstractMeasure\n    logweight :: R\n    base :: M\nend\n\n\n\n\n\n","category":"type"},{"location":"#MeasureTheory.:‚âÉ-Tuple{Any,Any}","page":"Home","title":"MeasureTheory.:‚âÉ","text":"‚âÉ(Œº,ŒΩ)\n\nEquivalence of Measure\n\nMeasures Œº and ŒΩ on the same space X are equivalent, written Œº ‚âÉ ŒΩ, if Œº ‚â™ ŒΩ and ŒΩ ‚â™ Œº.\n\nNote that this is often written ~ in the literature, but this is overloaded in probabilistic programming, so we use alternate notation.\n\n\n\n\n\n","category":"method"},{"location":"#MeasureTheory.:‚â™","page":"Home","title":"MeasureTheory.:‚â™","text":"‚â™(Œº,ŒΩ)\n\nAbsolute continuity\n\nThe following are equivalent:\n\nŒº ‚â™ ŒΩ\nŒº is absolutely continuous wrt ŒΩ\nThere exists a function f such that Œº = ‚à´f dŒΩ\n\n\n\n\n\n","category":"function"},{"location":"#MeasureTheory.basemeasure","page":"Home","title":"MeasureTheory.basemeasure","text":"basemeasure(Œº)\n\nMany measures are defined in terms of a logdensity relative to some base measure. This makes it important to be able to find that base measure.\n\nFor measures not defined in this way, we'll typically have basemeasure(Œº) == Œº.\n\n\n\n\n\n","category":"function"},{"location":"#MeasureTheory.isprimitive-Tuple{Any}","page":"Home","title":"MeasureTheory.isprimitive","text":"isprimitive(Œº)\n\nMost measures are defined in terms of other measures, for example using a density or a pushforward. Those that are not are considered (in this library, it's not a general measure theory thing) to be primitive. The canonical example of a primitive measure is Lebesgue(X) for some X.\n\nThe default method is     isprimitive(Œº) = false\n\nSo when adding a new primitive measure, it's necessary to add a method for its type that returns true.\n\n\n\n\n\n","category":"method"},{"location":"#MeasureTheory.logdensity","page":"Home","title":"MeasureTheory.logdensity","text":"logdensity(Œº::Measure{X}, x::X)\n\nCompute the logdensity of the measure Œº at the point x. This is the standard way to define logdensity for a new measure. the base measure is implicit here, and is understood to be basemeasure(Œº).\n\nMethods for computing density relative to other measures will be\n\n\n\n\n\n","category":"function"},{"location":"#MeasureTheory.‚à´-Tuple{Any,AbstractMeasure}","page":"Home","title":"MeasureTheory.‚à´","text":"‚à´(f, base::AbstractMeasure; log=true)\n\nDefine a new measure in terms of a density f over some measure base. If log=true (the default), f is considered as a log-density.\n\n\n\n\n\n","category":"method"},{"location":"#MeasureTheory.ùíπ-Tuple{AbstractMeasure,AbstractMeasure}","page":"Home","title":"MeasureTheory.ùíπ","text":"ùíπ(Œº::AbstractMeasure, base::AbstractMeasure; log=true)\n\nCompute the Radom-Nikodym derivative (or its log, if log=true) of Œº with respect to base.\n\n\n\n\n\n","category":"method"},{"location":"#MeasureTheory.@domain-Tuple{Any,Any}","page":"Home","title":"MeasureTheory.@domain","text":"@domain(name, T)\n\nDefines a new singleton struct T, and a value name for building values of that type.\n\nFor example, MeasureTheory.@domain ‚Ñù RealNumbers is equivalent to\n\nstruct RealNumbers <: MeasureTheory.AbstractDomain end\n\nexport ‚Ñù\n\n‚Ñù = MeasureTheory.RealNumbers()\n\nBase.show(io::IO, ::RealNumbers) = print(io, \"‚Ñù\")\n\n\n\n\n\n","category":"macro"},{"location":"#MeasureTheory.@measure-Tuple{Any}","page":"Home","title":"MeasureTheory.@measure","text":"@measure <declaration>\n\nThe <declaration> gives a measure and its default parameters, and specifies its relation to its base measure. For example,\n\n@measure Normal(Œº,œÉ) ‚âÉ Lebesgue{X}\n\ndeclares the Normal is a measure with default parameters Œº and œÉ, and it is equivalent to its base measure, which is Lebesgue{X}\n\nYou can see the generated code like this:\n\njulia> MacroTools.prettify(@macroexpand @measure Normal(Œº,œÉ) ‚âÉ Lebesgue{X})\nquote\n    struct Normal{P, X} <: AbstractMeasure\n        par::P\n    end\n    function Normal(nt::NamedTuple)\n        P = typeof(nt)\n        return Normal{P, eltype(Normal{P})}\n    end\n    Normal(; kwargs...) = Normal((; kwargs...))\n    (basemeasure(Œº::Normal{P, X}) where {P, X}) = Lebesgue{X}\n    Normal(Œº, œÉ) = Normal(; Any[:Œº, :œÉ])\n    ((:‚â™)(::Normal{P, X}, ::Lebesgue{X}) where {P, X}) = true\n    ((:‚â™)(::Lebesgue{X}, ::Normal{P, X}) where {P, X}) = true\nend\n\nNote that the eltype function needs to be defined separately by the user.\n\n\n\n\n\n","category":"macro"}]
}
