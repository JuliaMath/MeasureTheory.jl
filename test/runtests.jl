using Test
using StatsFuns
using Base.Iterators: take
using Random
using LinearAlgebra
using DynamicIterators: trace, TimeLift
using TransformVariables: transform, asð•€, inverse

if Base.VERSION â‰¥ v"1.6"
    @testset "No warnings on import" begin
        @test_nowarn @eval using MeasureTheory
    end
else
    @eval using MeasureTheory
end

function draw2(Î¼)
    x = rand(Î¼)
    y = rand(Î¼)
    while x == y
        y = rand(Î¼)
    end
    return (x,y)
end

@testset "Parameterized Measures" begin
    @testset "Binomial" begin
        D = Binomial{(:n, :p)}
        par = merge((n=20,),transform(asparams(D, (n=20,)), randn(1)))
        d = D(par)
        (n,p) = (par.n, par.p)
        logitp = logit(p)
        probitp = norminvcdf(p)
        y = rand(d)

        â„“ = logdensity(Binomial(;n, p), y)
        @test â„“ â‰ˆ logdensity(Binomial(;n, logitp), y)
        @test â„“ â‰ˆ logdensity(Binomial(;n, probitp), y)

        @test_broken logdensity(Binomial(n,p), CountingMeasure(â„¤[0:n]), x) â‰ˆ binomlogpdf(n,p,x)
    end

    @testset "NegativeBinomial" begin
        D = NegativeBinomial{(:r, :p)}
        par = transform(asparams(D), randn(2))
        d = D(par)
        (r,p) = (par.r, par.p)
        logitp = logit(p)
        Î» = p * r / (1 - p)
        y = rand(d)

        â„“ = logdensity(NegativeBinomial(;r, p), y)
        @test â„“ â‰ˆ logdensity(NegativeBinomial(;r, logitp), y)
        @test â„“ â‰ˆ logdensity(NegativeBinomial(;r, Î»), y)

        @test_broken logdensity(Binomial(n,p), CountingMeasure(â„¤[0:n]), x) â‰ˆ binomlogpdf(n,p,x)
    end

    @testset "Poisson" begin
        sample1 = rand(MersenneTwister(123), Poisson{(:logÎ»,)}(log(100)))
        sample2 = rand(MersenneTwister(123), Poisson{(:Î»,)}(100))
        @test sample1 == sample2
    end

    @testset "Normal" begin
        D = Normal{(:Î¼,:Ïƒ)}
        par = transform(asparams(D), randn(2))
        d = D(par)
        @test params(d) == par

        Î¼ = par.Î¼
        Ïƒ = par.Ïƒ
        ÏƒÂ² = Ïƒ^2
        Ï„ = 1/ÏƒÂ²
        logÏƒ = log(Ïƒ)
        y = rand(d)

        â„“ = logdensity(Normal(;Î¼,Ïƒ), y)
        @test â„“ â‰ˆ logdensity(Normal(;Î¼,ÏƒÂ²), y)
        @test â„“ â‰ˆ logdensity(Normal(;Î¼,Ï„), y)
        @test â„“ â‰ˆ logdensity(Normal(;Î¼,logÏƒ), y)
    end

    @testset "LKJCholesky" begin
        D = LKJCholesky{4}{(:Î·,)}
        par = transform(asparams(D), randn(1))
        d = D(par)
        @test params(d) == par

        Î·  = par.Î·
        logÎ· = log(Î·)

        y = rand(d)
        Î· = par.Î·
        â„“ = logdensity(LKJCholesky{4}(Î·), y)
        @test â„“ â‰ˆ logdensity(LKJCholesky{4}(logÎ·=logÎ·), y)
    end
end

@testset "Kernel" begin
    Îº = MeasureTheory.kernel(MeasureTheory.Dirac, identity)
    @test rand(Îº(1.1)) == 1.1
end

@testset "SpikeMixture" begin
    @test rand(SpikeMixture(Dirac(0), 0.5)) == 0
    @test rand(SpikeMixture(Dirac(1), 1.0)) == 1
    w = 1/3
    m = SpikeMixture(Normal(), w)
    bm = basemeasure(m)
    @test (bm.s*bm.w)*bm.m == 1.0*basemeasure(Normal())
    @test density(m, 1.0)*(bm.s*bm.w) == w*density(Normal(),1.0)
    @test density(m, 0)*(bm.s*(1-bm.w)) â‰ˆ (1-w)
end

@testset "Dirac" begin
    @test rand(Dirac(0.2)) == 0.2
    @test logdensity(Dirac(0.3), 0.3) == 0.0
    @test logdensity(Dirac(0.3), 0.4) == -Inf
end

@testset "For" begin
    FORDISTS = [
        For(1:10) do j Normal(Î¼=j) end
        For(4,3) do Î¼,Ïƒ Normal(Î¼,Ïƒ) end
        For(1:4, 1:4) do Î¼,Ïƒ Normal(Î¼,Ïƒ) end
        For(eachrow(rand(4,2))) do x Normal(x[1], x[2]) end
        For(rand(4), rand(4)) do Î¼,Ïƒ Normal(Î¼,Ïƒ) end
    ]

    for d in FORDISTS
        @test logdensity(d, rand(d)) isa Float64
    end
end

import MeasureTheory.:â‹…
function â‹…(Î¼::Normal, kernel) 
    m = kernel(Î¼)
    Normal(Î¼ = m.Î¼.Î¼, Ïƒ = sqrt(m.Î¼.Ïƒ^2 + m.Ïƒ^2))
end

"""
    ConstantMap(Î²)
Represents a function `f = ConstantMap(Î²)`
such that `f(x) == Î²`.
"""
struct ConstantMap{T}
    x::T
end
(a::ConstantMap)(x) = a.x
(a::ConstantMap)() = a.x

struct AffineMap{S,T}
    B::S
    Î²::T
end
(a::AffineMap)(x) = a.B*x + a.Î²
(a::AffineMap)(p::Normal) = Normal(Î¼ = a.B*mean(p) + a.Î², Ïƒ = sqrt(a.B*p.Ïƒ^2*a.B'))

@testset "DynamicFor" begin
    mc = Chain(Normal(Î¼=0.0)) do x Normal(Î¼=x) end
    r = rand(mc)
   
    # Check that `r` is now deterministic
    @test logdensity(mc, take(r, 100)) == logdensity(mc, take(r, 100))
    
    d2 = For(r) do x Normal(Î¼=x) end  

    @test_broken let r2 = rand(d2)
        logdensity(d2, take(r2, 100)) == logdensity(d2, take(r2, 100))
    end
end

@testset "Univariate chain" begin
    Î¾0 = 1.
    x = 1.2
    P0 = 1.0

    Î¦ = 0.8
    Î² = 0.1
    Q = 0.2

    Î¼ = Normal(Î¼=Î¾0, Ïƒ=sqrt(P0))
    kernel = MeasureTheory.kernel(Normal; Î¼=AffineMap(Î¦, Î²), Ïƒ=ConstantMap(Q))
    
    @test (Î¼ â‹… kernel).Î¼ == Normal(Î¼ = 0.9, Ïƒ = 0.824621).Î¼
    
    chain = Chain(kernel, Î¼)
    

    dyniterate(iter::TimeLift, ::Nothing) = dyniterate(iter, 0=>nothing) 
    tr1 = trace(TimeLift(chain), nothing, u -> u[1] > 15)
    tr2 = trace(TimeLift(rand(Random.GLOBAL_RNG, chain)), nothing, u -> u[1] > 15)
    collect(Iterators.take(chain, 10))
    collect(Iterators.take(rand(Random.GLOBAL_RNG, chain), 10))
end

@testset "Transforms" begin
    t = asð•€
    @testset "Pushforward" begin
        Î¼ = Normal()
        Î½ = Pushforward(t, Î¼)
        x = rand(Î¼)
        @test logdensity(Î¼, x) â‰ˆ logdensity(Pushforward(inverse(t), Î½), x)
    end

    @testset "Pullback" begin
        Î½ = Uniform()
        Î¼ = Pullback(t,Î½)
        y = rand(Î½)
        @test logdensity(Î½, y) â‰ˆ logdensity(Pullback(inverse(t), Î¼), y)
    end
end

using TransformVariables

@testset "Likelihood" begin
    dps = [
        (Normal()                             ,    2.0  )
        # (Pushforward(as((Î¼=asâ„,)), Normal()^1), (Î¼=2.0,))
    ]

    â„“s = [
        Likelihood(Normal{(:Î¼,)},              3.0)
        Likelihood(kernel(Normal, x -> (Î¼=x, Ïƒ=2.0)), 3.0)
    ]

    for (d,p) in dps
        for â„“ in â„“s
            @test logdensity(d âŠ™ â„“, p) == logdensity(d, p) + logdensity(â„“, p)
        end
    end
end
